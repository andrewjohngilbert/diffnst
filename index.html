<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Neural Style Transfer (NST) is the field of study applying neural techniques to modify the artistic appearance of a content image to match the style of a reference style image. Traditionally, NST methods have focused on texture-based image edits, affecting mostly low level information and keeping most image structures the same. ">
  <meta property="og:title" content="Diff-nst: Diffusion interleaving for deformable neural style transfer"/>
  <meta property="og:description" content="Neural Style Transfer (NST) is the field of study applying neural techniques to modify the artistic appearance of a content image to match the style of a reference style image. Traditionally, NST methods have focused on texture-based image edits, affecting mostly low level information and keeping most image structures the same. "/>
  <meta property="og:url" content="https://andrewjohngilbert.github.io/diffnst/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="assets/diffnst_teaser.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Diff-nst: Diffusion interleaving for deformable neural style transfer">
  <meta name="twitter:description" content="Neural Style Transfer (NST) is the field of study applying neural techniques to modify the artistic appearance of a content image to match the style of a reference style image. Traditionally, NST methods have focused on texture-based image edits, affecting mostly low level information and keeping most image structures the same. ">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="assets/diffnst_teaser.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon-32x32.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Diff-nst: Diffusion interleaving for deformable neural style transfer </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="F" target="_blank">Dan Ruta</a><sup>[1]</sup>,</span>
                <span class="author-block">
                  <a href="https://andrewjohngilbert.github.io/" target="_blank">Andrew Gilbert</a><sup>[1]</sup>,</span>
                  <span class="author-block">
                  <a href="https://scholar.google.co.uk/citations?user=Xzt0ib0AAAAJ&hl=en&inst=15262737669262836719&oi=sra" target="_blank">Gemma C Tarrés</a><sup>[1]</sup>,</span>
                  <span class="author-block">
                    <a href="https://research.adobe.com/person/eli-shechtman/" target="_blank">Eli Shechtman</a><sup>[2]</sup>,</span>
                    <span class="author-block">
                      <a href="https://scholar.google.com/citations?user=MqWYTj0AAAAJ" target="_blank">Nick Kolkin</a><sup>[2]</sup>,</span>
                  <span class="author-block">
                    <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/" target="_blank">John Collomosse</a>[1,2]
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Unviersity of Surrey<sup>[1]</sup>, Adobe Resarch<sup>[2]</sup><br><a href="https://eccv2024.ecva.net/" target="_blank">The European Conference of Computer Vision 2024</a> <a href="https://visarts.eu/index.php" target="_blank">Vision for Art (VISART VII) Workshop</a></span>
                

                    


                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://andrewjohngilbert.github.io/diffnst/assets/DIFF-NST_Diffusion_Interleaving_For_deFormable_Paper.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Presentation Slides PDF link -->
                  <span class="link-block">
                      <a href="static/pdfs/diffnst_pres.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Slides</span>
                    </a>
                  </span>
  
                  <!-- Github link -->
              <!--    <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              -->

                
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="assets/diggnst_teaserLarge.png">
      <h2 class="subtitle has-text-centered">
        Deformable style transfer using DIFF-NST, compared to baselines: NNST [13], CAST [41], NeAT [25], and PARASOL [31]. Our DIFF-NST method performs style transfer with much stronger style-based form alteration - matching the shapes and structures to those in the style image, not just the colors and textures.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Neural Style Transfer (NST) is the field of study applying neural techniques to modify the artistic appearance of a content image to match the style of a reference style image. Traditionally, NST methods have focused on texture-based image edits, affecting mostly low level information and keeping most image structures the same. However, style-based deformation of the content is desirable for some styles, especially in cases where the style is abstract or the primary concept of the style is in its deformed rendition of some content. With the recent introduction of diffusion models, such as Stable Diffusion, we can access far more powerful image generation techniques, enabling new possibilities. In our work, we propose using this new class of models to perform style transfer while enabling deformable style transfer, an elusive capability in previous models. We show how leveraging the priors of these models can expose new artistic controls at inference time, and we document our findings in exploring this new direction for the field of style transfer.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="assets/diffnst_overview.jpg">
      <h2 class="subtitle has-text-centered">
        High level visualization of our diffusion-based neural style transfer process. (left) Trainable MLP in the self-attention blocks of the LDM Unet modules. (right) Attention values and ALADIN style codes are extracted from the style image. The content image is re-colored by the style image, after which the LDM extracts content noises from it. These are interleaved into the reverse diffusion process at multiple time steps to generate a stylized version for the loss objective. Green modules are trainable, and blue modules are frozen.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Figure3 Image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="assets/diggnst_Fig3.png">
      <h2 class="subtitle has-text-centered">
        Visualization of style code ablation. The more disentangled ALADIN-NST embedding carries over less semantic information from the style images.
      </h2>
    </div>
  </div>
</section>
<!-- Figure3 Image-->

<!-- Figure4 Image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="assets/diggnst_Fig4.png">
      <h2 class="subtitle has-text-centered">
        Controlling the style-based content deformation of the stylized image at inference time by varying the starting timestep to apply pre-extracted content noises from the content image inversion.
      </h2>
    </div>
  </div>
</section>
<!-- Figure4 Image -->

<!-- Figure6 Image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="assets/diggnst_Fig6.png">
      <h2 class="subtitle has-text-centered">
        Deformable style transfer, comparing to NNST, CAST, NeAT, and PARASOL. All our figures are generated using images from the ALADIN-NST test set, which were not seen during training. More in the supplementary materials.
      </h2>
    </div>
  </div>
</section>
<!-- Figure6 Image -->


<!-- Paper poster -->
<!--
  <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->
-->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{Ruta:diffnst:ECCVWS:2024,
        AUTHOR = Ruta, Dan and  Tarrés, Gemma C and Gilbert, Andrew and Shechtman, Eli and Kolkin, Nick and Collomosse, John",
        TITLE = "Diff-nst: Diffusion interleaving for deformable neural style transfer",
        BOOKTITLE = "European Conference of Computer Vision 2024, Vision for Art (VISART VII) Workshop, 2024",
        YEAR = "2024",
        ​}</code></pre>
    </div>
</section>
<!--End BibTex citation -->




  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
